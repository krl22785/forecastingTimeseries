Homework 8
==========
*Kenneth Luna*

For this assignment, we will use the `forecast` and `tseries` libraries.

```{r}
library("forecast")
library("tseries")
```

The dataset is the exchange rate for the Indian Rupee to 1 U.S. Dollar.
The data is daily from July 1st, 2002 to April 8th, 2011.

```{r}
data <- read.csv("http://ptrckprry.com/course/forecasting/data/rupee.csv")
date <- as.Date(data$date, format="%m/%d/%Y")
time <- 1:length(date)
rupee <- data$rupee
```

We will work with the logs of the exchange rates:

```{r}
log.rupee <- log(rupee)
```


Problem 1
---------

Here is a time series plot of log.rupee, along with the ACF and PACF:

```{r}
par(mfrow=c(1,1))
plot(date, log.rupee, type="l",
     xlab="Date", ylab="log.rupee")

par(mfrow=c(1,2))
Acf(log.rupee)
Pacf(log.rupee)
```

Here is the first difference, along with the ACF and PACF:

```{r}
## Add code to compute the first difference and make the plots.
diff.log.rupee <- c(NA, diff(log.rupee))

par(mfrow=c(1,1))
plot(date, diff.log.rupee, type="l",
     xlab="Date", ylab="1st-Difference Log Rupee")

par(mfrow=c(1,2))
Acf(diff.log.rupee)
Pacf(diff.log.rupee)

```

Here is the second difference, along with the ACF and PACF:

```{r}
## Add code to compute the second difference and make the plots.
diff2.log.rupee <- c(NA, diff(diff.log.rupee))

par(mfrow=c(1,1))
plot(date, diff2.log.rupee, type="l",
     xlab="Date", ylab="2nd-Difference Log Rupee")

par(mfrow=c(1,2))
Acf(diff2.log.rupee)
Pacf(diff2.log.rupee)
```

**Does the series appear to be stationary?**

The series does not appear to be stationary.  Both the mean and the variance appear to change as time increases.  Furthermore, with the ACF gradually decaying and the first PACF is essentially 1, this apppears to be a random walk.  

**Can you identify an ARIMA(p,d,q) model from these plots?**

This model is an ARIMA(1,1,0) model based on the ACF and PACF charts.

Problem 2
---------

Here are the AICc for all ARIMA(p,1,q) models without constant for p and q
ranging from 0 to 2:


```{r}

d <- 1
aiccMin <- 0
# choose p, q with AICc
for (include.constant in c(FALSE, TRUE)) {
    for (p in 0:4) {
        for (q in 0:4) {
            # work-around bug in R by manually differencing
            fit <- Arima(diff(log.rupee), c(p,0,q), include.constant=include.constant, method="ML")
            cat("ARIMA(", p, ",", d, ",", q, ")(constant=", include.constant, ") : ", fit$aicc, "\n", sep="");
    
            if (fit$aicc < aiccMin)
              aiccMin <- fit$aicc      
        }
    }
}


print(aiccMin)
```

**Select an ARIMA(p,1,q) model.**

The best fitting model is the ARIMA(1,1,0) based on the AICC value of -17763.37.  This model does not contain a constant.   

Here is code to fit the model, then compute residuals and the fitted values:
```{r}
(fit.mean <- Arima(log.rupee, c(1,1,0), include.constant=FALSE, method="ML"))
```

Here are the residuals, with the last 10 residuals printed out:
```{r}
resid <- as.numeric(residuals(fit.mean))
tail(resid, n=10)
```

Here are the fitted values, with the last 10 fitted values printed out:
```{r}
f <- fitted.values(fit.mean)
tail(f, n=10)
```

Here is the one step ahead forecast and 95% forecast interval:

```{r}
forecast(fit.mean, h = 1, level = 95)
```


Problem 3
---------

Here is a plot of the residuals:
```{r}
# Add plot of the residuals.
par(mfrow=c(1,1))
plot(time, resid, type="l")
```

Here are an ACF and PACF of the residuals:

```{r}
par(mfrow=c(1,2))
Acf(resid)
Pacf(resid)
```

Here are an ACF and PACF of the squared residuals:

```{r}
par(mfrow=c(1,2))
Acf(resid^2)
Pacf(resid^2)
```

**Use these plots to argue that the residuals, although approximately
uncorrelated, are not independent; instead, they show evidence of conditional
heteroscedasticity.**

The ACF and PACF of the residual-squared show that there is not clear independence.  In moments when a shock or change in variance occurs, then that shock or variance remains constant for some period time after the first instance of it.  Again, although not correlated, this shows conditional hetereoscedasticity.  

The ACF and PACF for the residuals also shows signs of clusters where the variance deviates or increases over time indicating some structure that is not being acconted for.  


Problem 4
---------

Here are the AICc values for the ARCH(q):

```{r}
q <- 0:10
loglik <- rep(NA, length(q))
N <- length(resid)

for (i in 1:length(q)) {
    if (q[i] == 0) {
        loglik[i] <- -0.5 * N * (1 + log(2 * pi * mean(resid^2)))
    } else {
        fit <- garch(resid, c(0,q[i]), trace=FALSE)
        loglik[i] <- logLik(fit)
    }
}

k <- q + 1
aicc <- -2 * loglik  + 2 * k * N / (N - k - 1)

print(data.frame(q, loglik, aicc))

```

Here is the AICc for the GARCH(1,1):

```{r}
fit <- garch(resid, c(1,1), trace=FALSE)
loglik <- logLik(fit)
k <- 2
aicc <- -2 * loglik  + 2 * k * N / (N - k - 1)

print(data.frame(loglik, aicc))
```


Here are the summary and log likelihood of the selected model:

```{r}
fit.var <- garch(resid, c(1,1), trace=FALSE)
summary(fit.var)
logLik(fit.var)
```

**Comment on the statistical significance of the parameter values of your
selected model.**

The p-values for all of the coefficients is less than .05, therefore indicating that they are all statistically signifcant.  Something to take into consideration is how small Omega is for this formula.  It will close to 0.  

**x(t)^2 = 5.558e-08 + 1.327e-01 * eps(t-1)^2 + 8.859e-01 * x(t-1)^2**


Problem 5
---------

**Construct a 95% one step ahead forecast interval for the log exchange rate,
based on your ARIMA-ARCH model.**

```{r}
f1 <- as.numeric(forecast(fit.mean, h=1)$mean)

# Next, you need to determine the conditional variance, which we will store
# in a variable called "h1".
(omega <- coef(fit.var)[[1]])
(alpha <- coef(fit.var)[[2]])
(beta <- coef(fit.var)[[3]])
ht <- fit.var$fit[,1]^2 # ARIMA-ARCH

h1 <- omega + alpha * (resid^2)[2235] + beta * ht[2235]

f1 + c(-1, 1) * 1.96 * sqrt(h1)
```

**Compare this to the interval based on the ARIMA only model from Problem 2.**

The ARIMA-GARCH forecast is more specific versus the ARIMA model.  The forecast intervals deviate with the data instead of expanding like the ARIMA model when variance increases.  The ARIMA-GARCH model is better at capturing hetereoscedasticity of the model - rather than expanding the interval, it makes it more specific. 

Problem 6
---------

Here are the conditional variances, with the last 10 values printed out:

```{r}
ht <- fit.var$fit[,1]^2 # ARIMA-ARCH
tail(ht, n=10)
```

Here is a plot of the conditional variances:

```{r}
par(mfrow=c(1,2))
plot(date, diff.log.rupee, type="l", col=4)
plot(date, ht, type="l", col=4)
```

**Use this plot to locate bursts of high volatility.**


**Do these highly volatile periods agree with those found from examination of
the time series plot of the log exchange rates themselves?**

Yes, this model captures the same bursts (shocks) in volatility as compared to the original 1-st difference log.rupee plot.  


Problem 7
---------

Here is a time series plot which simultaneously shows the log exchange rates,
together with the ARIMA-GARCH one-step-ahead 95% forecast intervals based on
information available in the previous day:

```{r fig.width=12, fig.height=8}
par(mfrow=c(1,1))
plot(date, log.rupee, type="l")
lines(date, f + 1.96 * sqrt(ht), lty=2, col=2)
lines(date, f - 1.96 * sqrt(ht), lty=2, col=2)
```

**Using this plot, comment on the accuracy and practical usefulness of the
forecast intervals.**

This forecast is very accurate at capturing both changing means and changing variances.  The concern that I have with this model is that it might be overfitting; it might be soo good at finding an interval for a specific observation that it limits its efficacy and doing the same for future values. 


Problem 8
---------

Here is a normal probability plot of the ARCH residuals.

```{r}
resid.arch <- resid / sqrt(ht)

qqnorm(resid.arch, col=2)
qqline(resid.arch, col=1, lty=2)
```

**Does the model seem to have adequately described the leptokurtosis
("long-tailedness") in the data?**

The models falls slightly short at capturing the long-tailedness of the residuals based on the below the line and above the line observations.  

Problem 9
---------

Here is a count of how many prediction interval failures there were:

```{r}
sum(abs(log.rupee - f) > sqrt(ht) * 1.96, na.rm=TRUE)
```

The number of prediction intervals is:
```{r}
sum(!is.na(resid.arch))

113/2229
```

**What percentage of the time did the intervals fail?

About 5% of all intervals failed at forecasting the values.  

