311 Calls in 2015 
==========
*Kenneth Luna*

Going to use several packages for this project.  "plyr" allows for data summarization while ggplot improves on visualization capabilities. 

```{r}
library("forecast")
library("plyr") ## for data wrangling 
library("ggplot2") ## for data visualizations 
```

The dataset is the number of calls to 311 services in NYC pertaining to housing complaints.  

```{r}
data <- read.csv("/Users/krluna/forecastingTimeseries/Project1/311_data.csv")

data$count <- 1
data$Created.Date <- as.Date(data$Created.Date, "%m/%d/%Y")
tempdata <- ddply(data, c("Created.Date"), summarise, 
                 calls = length(count)
                 )

newdata <- tempdata[-c(211),]

date <- newdata$Created.Date
time <- 1:length(date)
calls <- newdata$calls
```

We now plot our initial data for exploration.  

```{r}

par(mfrow=c(1,1))
plot(date, calls, type="l",
     xlab="Date", ylab="311 Calls")

par(mfrow=c(1,2))
Acf(calls)
Pacf(calls)

```

Preliminary Observations

311 Calls does not seem to have any seasonality from January 1st 2015 until today.  The initial patterns that stand out of this preliminary plot are the spikes in early January and mid February.  Anecdotally, one might infer that this increase in calls to 311 is a function of adverse weather the in NYC Metropolitan Area, leading tenants to call and/or complain about lack of heating.  

There does appear to be some fluctation in call volume based on the day of the week.  The plot shows bumps with the occasional drop off each 6 or 7 days.  This trend holds true across the entire, minus the 3 or 4 observations that appear to be days that realized high call volumes. 

Based on this data set, we see that summer months do seem to be a bit quieter in terms of call volume.  September through October of 2014 appear to have lower call volumes but picks up come November.  

Based on the Auto-Correlation Function and Partial Auto-Correlation Function, we might suspect this plot to be an Auto-Regressive modeel.  The correlogram dies down while the parti correlogram cuts off after lag-1.  


```{r}

log.calls <- log(calls)
diff.log.calls <- c(NA, diff(log.calls))
diff2.log.calls <- c(NA, diff(diff.log.calls))

```

We decided to take logs instead of using absolute values in order to scale down some of the spikes in call volumes occurring in January and Febuary.  The two highest days in 311 calls were more than 3x larger than the average call volumne per day for this specific time period.  

```{r}

par(mfrow=c(1,1))
plot(date, log.calls, type="l",
     xlab="Date", ylab="Log(Calls)")

par(mfrow=c(1,2))
Acf(log.calls)
Pacf(log.calls)

```


Take the first difference:

```{r}

par(mfrow=c(1,1))
plot(date, diff.log.calls, type="l",
     xlab="Date", ylab="Diff. Log(Calls)")

par(mfrow=c(1,2))
Acf(diff.log.calls)
Pacf(diff.log.calls)

```

Take teh second difference: 

```{r}

par(mfrow=c(1,1))
plot(date, diff2.log.calls, type="l",
     xlab="Date", ylab="Diff2. Log(Calls)")

par(mfrow=c(1,2))
Acf(diff2.log.calls)
Pacf(diff2.log.calls)

```

Based on the ACF and PACF models for the first difference of log 311 calls, it appears we might have over-differenced as the first lag auto-correlation has a negative value.  The same holds true for the second difference.  

Based on this preliminary analysis, here are the AICC values for the models under consideration:


```{r}

fit.00 <- Arima(calls, c(0, 0, 0), include.constant=FALSE)
fit.01 <- Arima(calls, c(0, 0, 1), include.constant=FALSE)
fit.02 <- Arima(calls, c(0, 0, 2), include.constant=FALSE)
fit.10 <- Arima(calls, c(1, 0, 0), include.constant=FALSE)
fit.11 <- Arima(calls, c(1, 0, 1), include.constant=FALSE)
fit.12 <- Arima(calls, c(1, 0, 2), include.constant=FALSE)
fit.20 <- Arima(calls, c(2, 0, 0), include.constant=FALSE)
fit.21 <- Arima(calls, c(2, 0, 1), include.constant=FALSE)
fit.22 <- Arima(calls, c(2, 0, 2), include.constant=FALSE)

# With constant:
fit.00c <- Arima(calls, c(0, 0, 0), include.constant=TRUE)
fit.01c <- Arima(calls, c(0, 0, 1), include.constant=TRUE)
fit.02c <- Arima(calls, c(0, 0, 2), include.constant=TRUE)
fit.10c <- Arima(calls, c(1, 0, 0), include.constant=TRUE)
fit.11c <- Arima(calls, c(1, 0, 1), include.constant=TRUE)
fit.12c <- Arima(calls, c(1, 0, 2), include.constant=TRUE)
fit.20c <- Arima(calls, c(2, 0, 0), include.constant=TRUE)
fit.21c <- Arima(calls, c(2, 0, 1), include.constant=TRUE)
fit.22c <- Arima(calls, c(2, 0, 2), include.constant=TRUE)

models <- data.frame(p = rep(c(0, 0, 0, 1, 1, 1, 2, 2, 2), 2),
                     d = rep(0, 18),
                     q = rep(c(0, 1, 2), 6),
                     include.constant = c(rep(FALSE, 9), rep(TRUE, 9)),
                     loglik = c(fit.00$loglik, fit.01$loglik, fit.02$loglik,
                                fit.10$loglik, fit.11$loglik, fit.12$loglik,
                                fit.20$loglik, fit.21$loglik, fit.22$loglik,
                                fit.00c$loglik, fit.01c$loglik, fit.02c$loglik,
                                fit.10c$loglik, fit.11c$loglik, fit.12c$loglik,
                                fit.20c$loglik, fit.21c$loglik, fit.22c$loglik),
                     aicc = c(fit.00$aicc, fit.01$aicc, fit.02$aicc,
                                fit.10$aicc, fit.11$aicc, fit.12$aicc,
                                fit.20$aicc, fit.21$aicc, fit.22$aicc,
                                fit.00c$aicc, fit.01c$aicc, fit.02c$aicc,
                                fit.10c$aicc, fit.11c$aicc, fit.12c$aicc,
                                fit.20c$aicc, fit.21c$aicc, fit.22c$aicc)
                     )
```


The p, d, q selected based on AICC is the ARIMA(1,0,2) with constant with an AICC value of 3361.741.  

Here is the estimated model:
```{r}

fit <- Arima(calls, c(1,0,2), include.constant = TRUE)
print(fit)

(1-pnorm(abs(fit$coef)/sqrt(diag(fit$var.coef))))*2

```

Based on the coefficient values and the standard errors, it appears the ma1 coefficient is not statistically significant.  It has a z-value of less than 2 and its p-value is .2.  

[x(t) - 2056.6] = .9011 * [x(t-1) - 2056.6] + eps(t) + -.1231 * eps(t-1) + -.4004 * eps(t-2)


```{r}

resid <- residuals(fit)

Box.test(resid, lag=12, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=24, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=36, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=48, type = "Ljung-Box", fitdf=4)

```

The small p-values indicate dependence. 

```{r}
par(mfrow=c(1,1))
plot(date, resid, type="l")

par(mfrow=c(1,2))
Acf(resid)
Pacf(resid)
```

Forecast 

```{r}
par(mfrow=c(1,1))
plot(forecast(fit, h=30, level = 95))
```



Part E
------

Here are the Ljung-Box statistics for lack of fit:

```{r}

resid <- residuals(fit)

Box.test(resid, lag=12, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=24, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=36, type = "Ljung-Box", fitdf=4)

Box.test(resid, lag=48, type = "Ljung-Box", fitdf=4)

```

**Does the model seem to be adequate?**

The small p-values indicate dependence, therefore I would conclude that this model is inadequate for this analysis.  

Part F
------

Here is a plot of the residuals, along with the ACF and the PACF of the
residuals:

```{r}
par(mfrow=c(1,1))
plot(date, resid, type="l")

par(mfrow=c(1,2))
Acf(resid)
Pacf(resid)
```

**Do these plots indicate any inadequacies in the model?**

The plot for residuals on the fitted model seems to have a zero mean from just looking at it.  Based on these ACF and PACF plots, there does seem to be some inadequecies as some spikes extend outside of the significance limits, indicating they are more than just white noise.  


Part G
------

Here is the original data, along with the forecasts and 95% forecast intervals
for lead times 1 to 30:

```{r}
par(mfrow=c(1,1))
plot(forecast(fit, h=30, level = 95))
```

**Do the forecasts seem reasonable?**

The forecasts seems reasonable.  It shows a continuation of the trend for the last obserations with a drop in unemployment. 

**Do the forecast intervals seem excessively wide?**

I do believe the forecast seems a bit wide.  The bottom end of the 95% CI goes as low as the lowest record unemployment recording in this data and as high as the highest.  



